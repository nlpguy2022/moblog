import React from 'react';
import {useParams} from 'react-router-dom';
import { useLocation } from 'react-router-dom';

const postContent = {
    0: 'Generative AI is a model that uses AI to generate new content, whether it is text, image, audio, or video. These models rely on the Transformer architecture (Vaswani et al, 2017), a deep learning algorithm which had set state of the art performance on Computer Vision tasks and Natural Language Processing (NLP). This model enabled the development of various models like Google\'s BERT and OpenAI\'s GPT, which led to the development of ChatGPT, the poster child for Generative AI globally. The rise of ChatGPT brought for massive developments in the world of Generative AI, and aside from better Image and Language Models, we now also have Multimodal models like Open AI\'s GPT-4o, which has speech, text, and vision capabilities. Generative AI has transformed the way we do things. However, the wonders of Generative AI can only bear fruit when you make it work. Ultimately, Generative AI is still a massive probabilistic black box, and unfortunately shaking it on the first try may not get you the right answer. Thus, I will be taking you through some basic approaches you can leverage to make Generative AI work in your favor, particularly with Large Language Models (LLMs). In these few posts, we will be exploring how we, as layman, can leverage on Generative AI without having to go into the technical nitty-gritty of configuring how the system works (basically excluding the cool Data Science stuff but oh well :D). As a layman, the model is a magic box, and you are a magician.',
    1: 'We spoke about Generative AI, ChatGPT, and LLMs briefly in the previous post, and how you are responsible for making the model work. Think of the model as an intern that just joined your company. They can converse, do basic arithmetic, know some basic facts and trivia, but most likely are clueless about your company or what they have to do. Therefore, we as their supervisors need to make sure they understand what they need to do and how to do it to ensure they have a successful internship experience. In this post, we will explore a method called Prompt Engineering, which essentially provides the \'Whats\' and \'Hows\' to our \'interns\'. When we do prompt engineering, we pass the model an instruction set before asking it to do anything. This instruction set can include context about \'What\' the model needs to work on, \'How\' to work on it, as well as expectations of how it should answer. There are different ways to do prompt engineering, but I will describe three key types here: Zero-Shot Prompting, Few-Shot Prompting, and Chain-of-Thought (CoT) prompting. If you pass a basic instruction set to the model, that is Zero Shot prompting. If you pass the instruction set, but also give the model examples of how it should answer, that would be an example of Few Shot prompting. CoT is the more interesting way of prompting, where we basically help break down the instruction set into a process flow the model should follow, along with reasoning steps at each step in the process. This can be done in two ways, either by example (Few Shot Prompting with this breakdown of the instruction set and reasoning), or using Zero Shot CoT! You might be asking, how does Zero Shot CoT work? All you have to do is add \'Let\'s explain this step by step.\' at the end of your instruction set, and the model automatically understands that it needs to reason how it reached its conclusion. This is not a full-proof solution for every task, but it generally works well on a broad range of tasks! The key thing with Prompt Engineering is that you need to test out approaches iteratively to see which type gives you the most promising results. Start with the basics (Zero Shot Prompting), and increase the level of complexity of Prompt Engineering if needed. Also, make sure you test your models for consistency in its answers. These models typically have configurable parameters like \'temperature\' and \'top-p\', which define the creativity of the model and limit the choices of vocabulary for the model to generate respectively. These strategies should suffice for handling basic tasks, and are the first step to becoming a Generative AI magician!',
    2: 'We have already looked at Prompt Engineering previously as a means to customize our model to work on a given task. However, it is not always the case that the model will work just with Prompt Engineering. Let\'s head back to our intern analogy again: if you give an intern who is studying English work to do on Quantum Entanglement, they are most likely going to be a clueless duck no matter how much instruction you give to them! Similarly for the model, if it has never been trained on your data, probably won\'t be able to carry out your instructed task, no matter how many times you explain it to them. This is where Retrieval Augmented Generation (RAG) comes in. RAG enables us to add knowledge connectors to our model. This can be textual or image information, which is typically stored in something called a Vector Database (VectorDB), which does not need to be an actual database. Our knowledge is stored in this VectorDB in its raw form along with its embeddings (numeric vectors that represent our data), and based on the question or command we pass to the model, relevant knowledge should be retrieved by doing a similarity search (normally cosine similarity) over the embeddings in the VectorDB. You can choose what VectorDB is best suited for your requirements, but things to take into consideration are whether you want a static (top-k) or dynamic (maximal marginal relevance) retrieval of information. More importantly, something even more important is making sure your data is ready to be used in a RAG system. This means that your document is going to be split into chunks of relevant content to do meaningful retrieval. Chunking is typically done in RAG systems to make sure the content we pass to the model fits within its context window (the input size for the model). But chunking is hard. There is no golden chunking strategy, and you could start with something like page chunking or fixed size chunking, but the key thing is to ensure that each chunk should be as distinct as possible to ensure that information is not lost from chunk to chunk. However, the band-aid over the crack in RAG chunking is using a sufficient overlap size between chunks to try and mitigate potential information loss with chunking. Remember, this too is a empirical/testing driven framework, but should you master it you will have an insane amount of power over your models. (PRO TIP: Most players in industry are dabbling around here, as it is still cheaper than training your own model from scratch or generating data for fine tuning. With this, you should be well on your way through the core of the GenAI journey! Remember, the key is to be in control of the magic box as the magician. Good luck!',
    3: 'I have created a simple sandbox for you to test out your prompt engineering skills (RAG still pending hehehehe :D)! However, there are a few things you need to know before you can begin playing. Firstly, you need to know about System Prompting, which is our means of configuring the model to \'behave\' in a certain way. You can think of this as a means of adding a persona to the model so that they are configured to answer in a specific way. Secondly, we have the Prompt. This is our way of formatting the instructions we pass to the model. An example of this could be ensuring the model provides its answer in a bullet point list, or some other format. Lastly, there is the query, where you can input your question. Play around with this, and try out some prompting techniques to see if you can get the LLM to answer the way you want!',
    };

const Post = () => {
    const {id} = useParams();
    const location = useLocation();
    const { title } = location.state;
    const content = postContent[id] || 'Post not found';

    return (
        <div className="container">
            <article className='post'>
                <h2>Post #{id}: {title}</h2>
                <div className="post-meta">7 September 2024</div>
                <div className="post-content">
                    <p>{content}</p>
                </div>
            </article>
        </div>
    )
};

export default Post;